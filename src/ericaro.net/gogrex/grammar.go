package gogrex

import (
	"errors"
)

//grammar for the regexp
// we are gonna use the shunting yard algorithm

//Token interface that every token generated by a lexer should implement so that the shunting yard will reorder the incoming stream.
// All definitions are based on the Shunting Yard algorithm as defined by E.W Dijkstra
type Token interface {
	//Precedence return the precedence value of the given token.
	Precedence() int
	//IsOperator to separate between an operator and a value
	IsOperator() bool
	//IsLeaf a leaf is for all the identifiers and numbers 
	IsLeaf() bool
	//IsLeftParenthesis tells that this is an openning parenthesis symbol
	IsLeftParenthesis() bool
	//IsRightParenthesis tells that this is an closing parenthesis symbol
	IsRightParenthesis() bool
	//IsLeftAssociative left associative operator
	IsLeftAssociative() bool
	//	Error() error
}

//just to put a name on the type
type itemStack []Token

//pop retrieve one token from it
func (stack *itemStack) pop() (i Token, err error) {
	i, err = stack.peek()
	if err == nil {
		*stack = (*stack)[:len(*stack)-1]
	}
	return
}

//push append a item in the stack
func (stack *itemStack) push(x Token) {
	*stack = append(*stack, x)
}

//peek read the element from the stack but leave it.
func (stack *itemStack) peek() (i Token, err error) {
	if len(*stack) == 0 {
		return i, errors.New("Empty Stack")
	}
	return (*stack)[len(*stack)-1], nil
}

//shunting starts a go routine that read from the lex tokens, and push to the output chan. Tokens are simply reordered.
//so usually you start this goroutine, and read from the output chan from another one.
// if errors happens they are send to the err chan 
func shunting(tokens chan Token) (output chan Token, err chan error) {
	output = make(chan Token)
	err = make(chan error)
	go run(tokens, output, err)
	return
}


//run execute the shunting yard algorithm ( http://en.wikipedia.org/wiki/Shunting-yard_algorithm ) (no function support)
// it pops from the tokens, and write in the right order into the output chan, errors are pushed to the errchan
func run(tokens chan Token, output chan Token, errchan chan error) {
	stack := itemStack(make([]Token, 0, 10))
	for token := range tokens {
		switch {
		case token.IsLeaf(): // usually a number in shunting yard, or an identifier
			output <- token
		//case token.IsFunction(): stack.push(token) // ignored for now, I don't need to support function call
		//If the token is an operator, o1, then:
		case token.IsOperator():
			o2, err := stack.peek()
			for err == nil && (( // while there is an operator token, o2,at the top of the stack, and
			//o1 is left-associative and its precedence is less than or equal to that of o2,
			token.IsLeftAssociative() && token.Precedence() <= o2.Precedence()) || (
			//o1 has precedence less than that of o2,
			token.Precedence() < o2.Precedence())) {
				stack.pop()
				output <- o2
				o2, err = stack.peek()
			}
			stack.push(token)
		//If the token is a left parenthesis, then push it onto the stack.
		case token.IsLeftParenthesis():
			//fmt.Printf("is left\n")
			stack.push(token)
		//If the token is a right parenthesis:
		case token.IsRightParenthesis():
			o2, err := stack.peek()
			for err == nil && !o2.IsLeftParenthesis() { //Until the token at the top of the stack is a left parenthesis, 
				//pop operators off the stack onto the output queue.
				stack.pop()
				output <- o2
				o2, err = stack.peek()
			}
			if !o2.IsLeftParenthesis() {
				errchan <- errors.New("parenthesis mismatch")
			}
			stack.pop()

			//		case token.typ.nature == typeEOF:
			//			close(output)
		}
	}
	for len(stack) > 0 {
		pop, err := stack.pop()
		if err != nil || pop.IsLeftParenthesis() || pop.IsRightParenthesis() {
			errchan <- errors.New("parenthesis mismatch")
		} // this is an error
		output <- pop
	}
	close(output)
	close(errchan)
	return
}
